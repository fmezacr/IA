{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvUsOZYwB3jYEfF+kWwJUw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fmezacr/IA/blob/main/Lab_1_ASTROai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clasificación de Objetos Celestes con Machine Learning: Aplicando Redes Neuronales y Random Forest a Datos Reales del SDSS**\n",
        "\n",
        "### **Introducción**\n",
        "El objetivo de esta notebook es aplicar técnicas de Machine Learning (ML) para resolver un problema de clasificación en astronomía, utilizando datos reales del **Sloan Digital Sky Survey (SDSS)**. En este caso, clasificaremos objetos celestes en tres categorías:\n",
        "- **Estrellas (STAR)**\n",
        "- **Galaxias (GALAXY)**\n",
        "- **Cuásares (QSO)**\n"
      ],
      "metadata": {
        "id": "ijggsDF4_8rC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 1: Acceso y Preprocesamiento de Datos**\n",
        "\n",
        "**Descripción:**\n",
        "- Los datos del SDSS se obtienen a través de consultas SQL usando `astroquery`.\n",
        "- Seleccionamos características observacionales (`u, g, r, i, z`) y las etiquetas (`class`).\n",
        "- Mapeamos las etiquetas a valores categóricos (`0, 1, 2`) para facilitar su uso en los modelos.\n"
      ],
      "metadata": {
        "id": "KBzR-Y5LADdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from astroquery.sdss import SDSS\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Consulta SQL para obtener datos del SDSS\n",
        "query = \"\"\"\n",
        "SELECT TOP 1000\n",
        "  p.objID, p.u, p.g, p.r, p.i, p.z,\n",
        "  s.class as class\n",
        "FROM PhotoObj AS p\n",
        "  JOIN SpecObj AS s ON s.bestobjid = p.objid\n",
        "WHERE s.class IN ('STAR', 'GALAXY', 'QSO')\n",
        "\"\"\"\n",
        "sdss_data = SDSS.query_sql(query)  # Ejecutar la consulta\n",
        "data = sdss_data.to_pandas()       # Convertir a DataFrame\n",
        "print(data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "0kRPaWGQAHDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento: Selección de columnas y transformación de etiquetas\n",
        "data = data[[\"u\", \"g\", \"r\", \"i\", \"z\", \"class\"]].dropna()\n",
        "data[\"class\"] = data[\"class\"].map({\"STAR\": 0, \"GALAXY\": 1, \"QSO\": 2})\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "FooTWzeXFDzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 2: División de Datos**\n",
        "\n",
        "**Descripción:**\n",
        "- Dividimos los datos en:\n",
        "  - **Conjunto de entrenamiento:** Usado para ajustar el modelo.\n",
        "  - **Conjunto de prueba:** Usado para evaluar el rendimiento del modelo.\n",
        "- Utilizamos el 80% de los datos para entrenamiento y el 20% para prueba."
      ],
      "metadata": {
        "id": "8g-_Fo4TAXrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data[[\"u\", \"g\", \"r\", \"i\", \"z\"]]  # Características\n",
        "y = data[\"class\"]                     # Etiquetas\n",
        "\n",
        "# División en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"Conjunto de entrenamiento:\", X_train.shape, y_train.shape)\n",
        "print(\"Conjunto de prueba:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "FcY6Wrt4AY3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 3: Modelo de Machine Learning - Random Forest**\n",
        "\n",
        "**Descripción:**\n",
        "- Entrenamos un modelo Random Forest para clasificar los objetos celestes.\n",
        "- Este modelo utiliza múltiples árboles de decisión para tomar decisiones robustas."
      ],
      "metadata": {
        "id": "S29aCtD_AkgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "#TO DO implemente una arquitectura de Clasificador Random Forrest, empiece con 100 árboles.\n",
        "rf_model =\n",
        "\n",
        "# TO DO Aplique el FIT\n",
        "\n",
        "\n",
        "# Predicciones y evaluación\n",
        "# TO DO Haga las predicciones\n",
        "y_pred_rf =\n",
        "\n",
        "print(\"Reporte de Clasificación (Random Forest):\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "haEeoQBYAlRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 4: Modelo de Machine Learning - Red Neuronal Artificial (ANN)**\n",
        "\n",
        "**Descripción:**\n",
        "- Entrenamos una red neuronal para clasificar los objetos.\n",
        "- Configuración:\n",
        "  - Entrada: 5 características (`u, g, r, i, z`).\n",
        "  - Capas ocultas: 16 y 8 neuronas respectivamente.\n",
        "  - Salida: 3 neuronas (una por cada clase)."
      ],
      "metadata": {
        "id": "AUUJwN_yAw0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Estandarizar las características\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Crear modelo ANN mejorado\n",
        "ann_model = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),  # Capa de entrada -- Es equivalente a \"Input(shape=(5,))\"\n",
        "    #Ingrese aquí el código,  # Capa oculta 1 con 32 neuronas y RELU como función de activición\n",
        "    #Ingrese aquí el código,                  # Dropout 0.3 para evitar sobreajuste\n",
        "    #Ingrese aquí el código,  # Capa oculta 2 con 16 neuronas y RELU como función de activición\n",
        "    #Ingrese aquí el código,                  # Dropout 0.2 para evitar sobreajuste\n",
        "    #Ingrese aquí el código,   # Capa oculta 3 con 8 neuronas y RELU como función de activición\n",
        "    #Ingrese aquí el código # Capa de salida para clasificación multiclase\n",
        "])\n",
        "\n",
        "# Compilar el modelo con optimizador mejorado\n",
        "ann_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Usar early stopping para detener el entrenamiento si no hay mejora\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento del modelo con más épocas\n",
        "history = ann_model.fit(\n",
        "    X_train_scaled, y_train_enc,\n",
        "    validation_split=0.2,  # Validación durante el entrenamiento\n",
        "    epochs=400,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predicción con ANN mejorada\n",
        "y_pred_ann = np.argmax(ann_model.predict(X_test_scaled), axis=-1)  #  argmax para onvertir las probabilidades de salida de una red en una predicción de clase.\n",
        "\n",
        "# Evaluación del modelo mejorado\n",
        "print(\"Reporte de Clasificación (ANN Mejorada):\")\n",
        "print(classification_report(y_test, y_pred_ann, zero_division=0))\n",
        "\n",
        "# Graficar precisión (accuracy) durante el entrenamiento\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['accuracy'], label='Accuracy de Entrenamiento', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Accuracy de Validación', color='orange')\n",
        "plt.title('Precisión del Modelo vs Épocas', fontsize=14)\n",
        "plt.xlabel('Épocas', fontsize=12)\n",
        "plt.ylabel('Precisión', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cBOWl1rkCfbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 5: Visualización de Resultados**\n",
        "\n",
        "**Descripción:**\n",
        "- Usamos matrices de confusión para comparar los errores y aciertos de cada modelo.\n",
        "- Una matriz de confusión muestra las predicciones correctas (diagonal) y los errores (fuera de la diagonal).\n"
      ],
      "metadata": {
        "id": "Va4qwOeJDHVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Matriz de confusión para Random Forest\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rf, display_labels=[\"STAR\", \"GALAXY\", \"QSO\"])\n",
        "plt.title(\"Matriz de Confusión: Random Forest\")\n",
        "plt.show()\n",
        "\n",
        "# Matriz de confusión para ANN\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_ann, display_labels=[\"STAR\", \"GALAXY\", \"QSO\"])\n",
        "plt.title(\"Matriz de Confusión: ANN\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aaeM_-NPDKg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 6: Conclusiones y Recomendaciones**\n",
        "\n",
        "**Conclusiones:**\n",
        "1. **Random Forest:**\n",
        "   - Es rápido y preciso con los datos disponibles.\n",
        "   - Suficientemente robusto para clasificaciones iniciales.\n",
        "\n",
        "2. **ANN:**\n",
        "   - Ofrece resultados comparables, pero puede mejorar con más datos.\n",
        "   - Captura relaciones complejas gracias a su naturaleza no lineal.\n",
        "\n",
        "**Recomendaciones:**\n",
        "- **Más Datos:** Incorporar datos adicionales como velocidad radial y desplazamiento al rojo.\n",
        "- **Ajuste de Hiperparámetros:** Optimizar parámetros como número de árboles, neuronas, y tasas de aprendizaje.\n",
        "- **Modelos Avanzados:** Explorar técnicas como Gradient Boosting o redes neuronales profundas.\n",
        "\n"
      ],
      "metadata": {
        "id": "KAHlAq0qDZog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ANEXOS**"
      ],
      "metadata": {
        "id": "dt0yeN8XFQf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Consulta SQL**\n",
        "```sql\n",
        "SELECT TOP 1000\n",
        "  p.objID, p.u, p.g, p.r, p.i, p.z,\n",
        "  s.class as class\n",
        "FROM PhotoObj AS p\n",
        "  JOIN SpecObj AS s ON s.bestobjid = p.objid\n",
        "WHERE s.class IN ('STAR', 'GALAXY', 'QSO')\n",
        "```\n",
        "\n",
        "### **Partes de la Consulta**\n",
        "\n",
        "1. **`SELECT TOP 1000`**\n",
        "   - Indica que queremos obtener **los primeros 1000 registros** de los datos que coincidan con los criterios.\n",
        "   - Esto es útil para limitar el tamaño del conjunto y garantizar que la consulta sea eficiente, especialmente si trabajamos en Google Colab con recursos limitados.\n",
        "\n",
        "\n",
        "2. **Columnas Seleccionadas**\n",
        "   ```sql\n",
        "   p.objID, p.u, p.g, p.r, p.i, p.z, s.class as class\n",
        "   ```\n",
        "   - Estas son las columnas que queremos incluir en los resultados:\n",
        "     - **`p.objID`**: Identificador único del objeto celeste.\n",
        "     - **`p.u, p.g, p.r, p.i, p.z`**: Magnitudes en diferentes bandas del espectro:\n",
        "       - **u**: Ultravioleta.\n",
        "       - **g**: Verde.\n",
        "       - **r**: Rojo.\n",
        "       - **i**: Infrarrojo cercano.\n",
        "       - **z**: Infrarrojo profundo.\n",
        "       Estas magnitudes son medidas logarítmicas del brillo observado en cada banda.\n",
        "     - **`s.class as class`**: Clase del objeto celeste:\n",
        "       - **STAR**: Estrella.\n",
        "       - **GALAXY**: Galaxia.\n",
        "       - **QSO**: Cuásar.\n",
        "\n",
        "\n",
        "3. **`FROM PhotoObj AS p`**\n",
        "   - Especifica la tabla **`PhotoObj`** como fuente principal de datos. Esta tabla contiene información fotométrica (e.g., magnitudes, posición) de los objetos detectados.\n",
        "\n",
        "\n",
        "4. **`JOIN SpecObj AS s ON s.bestobjid = p.objid`**\n",
        "   - Realiza una **unión** entre las tablas `PhotoObj` y `SpecObj`.\n",
        "   - **`SpecObj`** contiene información espectroscópica, incluyendo la clase del objeto (*STAR, GALAXY, QSO*).\n",
        "   - La unión se basa en el campo **`bestobjid`**, que conecta los datos fotométricos de un objeto en `PhotoObj` con sus datos espectroscópicos en `SpecObj`.\n",
        "\n",
        "\n",
        "5. **`WHERE s.class IN ('STAR', 'GALAXY', 'QSO')`**\n",
        "   - Filtra los resultados para incluir únicamente objetos cuya clase espectroscópica sea:\n",
        "     - **`STAR`**: Estrella.\n",
        "     - **`GALAXY`**: Galaxia.\n",
        "     - **`QSO`**: Cuásar (núcleo galáctico activo).\n",
        "   - Esto garantiza que solo obtenemos los tres tipos de objetos relevantes para la clasificación.\n",
        "\n",
        "   ---"
      ],
      "metadata": {
        "id": "KNtelhi1FTAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Estructura de la Matriz de Confusión (Random Forrest)**\n",
        "1. **Ejes:**\n",
        "   - **Eje Y (\"True label\")**: Representa las clases reales (verdaderas) de los datos.\n",
        "   - **Eje X (\"Predicted label\")**: Representa las clases predichas por el modelo.\n",
        "\n",
        "2. **Valores:**\n",
        "   - Cada celda contiene el número de ejemplos clasificados en una combinación de clase real y predicción.\n",
        "\n",
        "\n",
        "### **Interpretación Celda por Celda**\n",
        "1. **Diagonal Principal (42, 104, 8):**\n",
        "   - Estos son los **aciertos** del modelo.\n",
        "   - Ejemplos clasificados correctamente como:\n",
        "     - **42** estrellas.\n",
        "     - **104** galaxias.\n",
        "     - **8** cuásares.\n",
        "\n",
        "2. **Fuera de la Diagonal:**\n",
        "   - Estas son las **confusiones** o errores del modelo.\n",
        "   - Ejemplos:\n",
        "     - **16** estrellas fueron clasificadas erróneamente como galaxias.\n",
        "     - **13** galaxias fueron clasificadas como estrellas.\n",
        "     - **8** cuásares fueron clasificadas como estrellas.\n",
        "     - **6** cuásares fueron clasificadas como galaxias.\n",
        "\n",
        "\n",
        "### **Cálculo de Métricas Clave**\n",
        "Con base en la matriz, se pueden calcular métricas para evaluar el rendimiento del modelo:\n",
        "\n",
        "\n",
        "#### 1. **Precisión por Clase**\n",
        "   Proporción de predicciones correctas sobre todas las predicciones realizadas para esa clase.\n",
        "\n",
        "   - **STAR**:\n",
        "$$\n",
        "     \\text{Precisión}_{\\text{STAR}} = \\frac{42}{42 + 13 + 8} = \\frac{42}{63} \\approx 0.67 \\, (67\\%)\n",
        "$$\n",
        "   - **GALAXY**:\n",
        "$$\n",
        "     \\text{Precisión}_{\\text{GALAXY}} = \\frac{104}{104 + 16 + 6} = \\frac{104}{126} \\approx 0.83 \\, (83\\%)\n",
        "$$\n",
        "   - **QSO**:\n",
        "$$\n",
        "     \\text{Precisión}_{\\text{QSO}} = \\frac{8}{8 + 3 + 0} = \\frac{8}{11} \\approx 0.73 \\, (73\\%)\n",
        "$$\n",
        "\n",
        "#### 2. **Recall (Exhaustividad) por Clase**\n",
        "   Proporción de aciertos sobre el total de ejemplos reales en esa clase.\n",
        "\n",
        "   - **STAR**:\n",
        "$$\n",
        "     \\text{Recall}_{\\text{STAR}} = \\frac{42}{42 + 16 + 0} = \\frac{42}{58} \\approx 0.72 \\, (72\\%)\n",
        "$$\n",
        "   - **GALAXY**:\n",
        "$$\n",
        "     \\text{Recall}_{\\text{GALAXY}} = \\frac{104}{13 + 104 + 3} = \\frac{104}{120} \\approx 0.87 \\, (87\\%)\n",
        "$$\n",
        "   - **QSO**:\n",
        "$$\n",
        "     Recall_{QSO} = \\frac{8}{8 + 6 + 8} = \\frac{8}{22} \\approx 0.36\\,(36\\%)\n",
        "$$\n",
        "\n",
        "\n",
        "#### 3. **F1-Score**:\n",
        "   La media armónica entre precisión y recall. Es útil para clases desbalanceadas:\n",
        "   $$\n",
        "   F1 = 2 \\cdot \\frac{\\text{Precisión} \\cdot \\text{Recall}}{\\text{Precisión} + \\text{Recall}}\n",
        "   $$\n",
        "\n",
        "### **Conclusiones de esta Matriz**\n",
        "1. **Fortalezas:**\n",
        "   - El modelo clasifica muy bien las **galaxias** (alta precisión y recall).\n",
        "   - La clase **estrellas** tiene un rendimiento decente, aunque hay confusiones con galaxias.\n",
        "\n",
        "2. **Debilidades:**\n",
        "   - La clase **cuásares (QSO)** es el punto débil del modelo:\n",
        "     - Bajo recall (36%): El modelo falla en detectar muchos cuásares.\n",
        "     - Esto puede deberse a que los cuásares son menos frecuentes y/o sus características son similares a las de otras clases.\n",
        "\n",
        "3. **Acciones de Mejora:**\n",
        "   - **Balancear las Clases**: Si las clases están desbalanceadas, usar técnicas como oversampling (aumentar datos de cuásares) o ponderación de clases en el modelo.\n",
        "   - **Incluir Más Características**: Agregar más datos observacionales (como redshift o velocidad radial) podría mejorar la clasificación de cuásares.\n",
        "   - **Modelo Más Complejo**: Probar con modelos más avanzados, como Gradient Boosting o redes neuronales profundas.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GpHXZhe6FaMg"
      }
    }
  ]
}